# File: enhanced_nlp_ai_module.py
"""
Enhanced NLP + AI Integration Module for Deforum Music Generator

This module augments a baseline AudioAnalyzer (from your existing
`enhanced_deforum_music_generator2.py`) with transformer-driven NLP
and optional Claude-powered prompt generation while preserving
backward compatibility with your current JSON outputs and UI.

Highlights
- Multi-backend NLP (spaCy, Transformers, TextBlob, NLTK) with graceful fallbacks
- Emotion detection with transformer classifiers
- Zero-shot theme classification
- Named Entity Recognition (NER) for people/places/objects
- Sentiment analysis + progression across lyric segments
- Simple narrative structure inference via zero-shot labels
- Optional Claude API prompt generation with transparent fallback

Usage (inside enhanced_deforum_music_generator2.py)
-----------------------------------------------------------------
from enhanced_nlp_ai_module import (
    EnhancedNLPAnalyzer,
    AIPromptGenerator,
    LyricsAnalysis,
    integrate_enhanced_nlp,
)

# Create an enhanced analyzer class that wraps your existing one
EnhancedAudioAnalyzer = integrate_enhanced_nlp(AudioAnalyzer)

# Use it when wiring the UI / CLI
analyzer = EnhancedAudioAnalyzer(max_duration=MAX_AUDIO_DURATION, claude_api_key=os.getenv("ANTHROPIC_API_KEY"))

# When running analysis
analysis = analyzer.analyze(audio_path, enable_lyrics=True, enable_ai_prompts=True)
# -> analysis.enhanced_lyrics will be populated; prompts can be generated by AIPromptGenerator

Dependencies (optional but recommended)
-----------------------------------------------------------------
- spaCy:          pip install spacy  &&  python -m spacy download en_core_web_sm
- transformers:   pip install transformers torch
- TextBlob:       pip install textblob  &&  python -m textblob.download_corpora
- NLTK VADER:     pip install nltk     &&  python -c "import nltk; nltk.download('vader_lexicon')"
- requests:       pip install requests  (for Claude HTTP API)

The module degrades gracefully if any dependency is missing.
"""
from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple
import json
import os
import re

# -------- Optional dependency detection (all soft) --------
try:
    import spacy  # type: ignore
    _SPACY_OK = True
except Exception:
    spacy = None
    _SPACY_OK = False

try:
    from transformers import pipeline  # type: ignore
    _TF_OK = True
except Exception:
    pipeline = None
    _TF_OK = False

try:
    from textblob import TextBlob  # type: ignore
    _TB_OK = True
except Exception:
    TextBlob = None
    _TB_OK = False

try:
    import nltk  # type: ignore
    from nltk.sentiment import SentimentIntensityAnalyzer  # type: ignore
    _NLTK_OK = True
except Exception:
    nltk = None
    SentimentIntensityAnalyzer = None
    _NLTK_OK = False

try:
    import requests  # type: ignore
    _REQ_OK = True
except Exception:
    requests = None
    _REQ_OK = False

try:
    from .core.ai_providers import AIProviderConfig, build_ai_provider
    _AI_PROVIDER_OK = True
except Exception:
    AIProviderConfig = None
    build_ai_provider = None
    _AI_PROVIDER_OK = False


# ---------------------------------------------------------------------------
# Data container returned on enhanced analysis
# ---------------------------------------------------------------------------
@dataclass
class LyricsAnalysis:
    """Rich, structured NLP results used to enhance prompts.

    Fields are intentionally generic to avoid coupling to any single NLP lib.
    """
    # Core classifiers
    emotions: List[str] = field(default_factory=list)
    emotion_scores: Dict[str, float] = field(default_factory=dict)
    themes: List[str] = field(default_factory=list)
    theme_scores: Dict[str, float] = field(default_factory=dict)

    # Entities + imagery
    entities: Dict[str, List[str]] = field(default_factory=dict)  # e.g., {"PERSON": [...], "GPE": [...]} 
    visual_imagery: List[str] = field(default_factory=list)       # distilled visual nouns/phrases

    # Sentiment
    sentiment_scores: Dict[str, float] = field(default_factory=dict)  # overall polarity, subjectivity, vader compound
    sentiment_progression: List[Tuple[int, float]] = field(default_factory=list)  # (segment_idx, score)

    # Narrative
    narrative_structure: str = ""

    # AI prompts (optional)
    ai_generated_prompts: List[str] = field(default_factory=list)

    # Diagnostics
    warnings: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "emotions": self.emotions,
            "emotion_scores": self.emotion_scores,
            "themes": self.themes,
            "theme_scores": self.theme_scores,
            "entities": self.entities,
            "visual_imagery": self.visual_imagery,
            "sentiment_scores": self.sentiment_scores,
            "sentiment_progression": self.sentiment_progression,
            "narrative_structure": self.narrative_structure,
            "ai_generated_prompts": self.ai_generated_prompts,
            "warnings": self.warnings,
        }


# ---------------------------------------------------------------------------
# Enhanced NLP Analyzer
# ---------------------------------------------------------------------------
class EnhancedNLPAnalyzer:
    """Performs advanced NLP over lyric text with multi-backend fallbacks.

    The analyzer attempts the strongest available method first and degrades
    gracefully. Long texts are handled by chunking where appropriate.
    """

    # Reasonable, compact default label sets for zero-shot tasks
    DEFAULT_THEMES: List[str] = [
        "love", "heartbreak", "freedom", "nostalgia", "rebellion",
        "urban adventure", "nature and environment", "personal growth",
        "party", "loneliness", "friendship", "self-empowerment",
        "melancholy", "hope", "anger",
    ]
    NARRATIVE_LABELS: List[str] = [
        "exposition", "rising action", "climax", "falling action",
        "resolution", "nonlinear montage", "vignette"
    ]

    # Common visual keywords used as a safety net when NER/noun-chunks are absent
    VISUAL_KEYWORDS: List[str] = [
        "sky", "sun", "moon", "ocean", "sea", "beach", "mountain",
        "city", "river", "forest", "rain", "fire", "light", "shadow",
        "flower", "street", "neon", "storm", "desert", "night",
    ]

    # Several viable emotion models; we try in order
    EMOTION_MODELS: List[str] = [
        "j-hartmann/emotion-english-distilroberta-base",
        "SamLowe/roberta-base-go_emotions",
        "joeddav/distilbert-base-uncased-go-emotions-student",
    ]

    def __init__(self, spacy_model: str = "en_core_web_sm", theme_labels: Optional[List[str]] = None):
        self._spacy_model_name = spacy_model
        self._nlp = None
        if _SPACY_OK:
            try:
                self._nlp = spacy.load(spacy_model)
            except Exception:
                # Model not downloaded; keep None and fall back
                self._nlp = None

        self._emotion_pipe = None
        self._zshot_pipe = None
        self._ensure_pipelines()

        self.theme_labels = theme_labels or self.DEFAULT_THEMES

    # ---------- public ----------
    def analyze_text(self, text: str) -> LyricsAnalysis:
        la = LyricsAnalysis()
        if not text or not text.strip():
            la.warnings.append("No text provided for NLP analysis.")
            return la

        # Normalize whitespace and create segments
        clean = self._clean_text(text)
        segments = self._segment_text(clean)

        # Emotions
        emo_labels, emo_scores = self._emotion_analysis(clean)
        la.emotions = emo_labels
        la.emotion_scores = emo_scores

        # Themes (zero-shot)
        theme_labels, theme_scores = self._themes_zero_shot(clean)
        la.themes = theme_labels
        la.theme_scores = theme_scores

        # NER + imagery
        ents = self._extract_entities(clean)
        imagery = self._extract_visual_imagery(clean, ents)
        la.entities = ents
        la.visual_imagery = imagery

        # Sentiment
        sent_overall, sent_prog = self._sentiment(clean, segments)
        la.sentiment_scores = sent_overall
        la.sentiment_progression = sent_prog

        # Narrative structure
        la.narrative_structure = self._narrative_structure(clean)

        return la

    # ---------- internals ----------
    def _ensure_pipelines(self) -> None:
        if _TF_OK and self._emotion_pipe is None:
            # try multiple models
            for model_name in self.EMOTION_MODELS:
                try:
                    self._emotion_pipe = pipeline(
                        "text-classification",
                        model=model_name,
                        return_all_scores=True,
                        truncation=True,
                        framework="pt",
                    )
                    break
                except Exception:
                    self._emotion_pipe = None
                    continue
        if _TF_OK and self._zshot_pipe is None:
            try:
                self._zshot_pipe = pipeline(
                    "zero-shot-classification",
                    model="facebook/bart-large-mnli",
                    truncation=True,
                    framework="pt",
                )
            except Exception:
                self._zshot_pipe = None

    @staticmethod
    def _clean_text(text: str) -> str:
        # Remove repeated whitespace and weird control chars
        t = re.sub(r"[\r\t]+", " ", text)
        t = re.sub(r"\n{2,}", "\n", t)
        return t.strip()

    @staticmethod
    def _segment_text(text: str, max_len: int = 400) -> List[str]:
        # Split by blank lines or periods; keep segments small for per-segment sentiment
        raw = [s.strip() for s in re.split(r"\n\s*\n|\.\s+", text) if s.strip()]
        segments: List[str] = []
        cur = ""
        for s in raw:
            if len(cur) + len(s) <= max_len:
                cur = (cur + " " + s).strip()
            else:
                if cur:
                    segments.append(cur)
                cur = s
        if cur:
            segments.append(cur)
        return segments or [text]

    def _emotion_analysis(self, text: str) -> Tuple[List[str], Dict[str, float]]:
        if self._emotion_pipe is not None:
            try:
                outputs = self._emotion_pipe(text[:4000])  # guard extremely long inputs
                # Some models return list[list[dict]]; normalize to single list
                if outputs and isinstance(outputs[0], dict):
                    scores = {d["label"].lower(): float(d["score"]) for d in outputs}
                else:
                    # outputs[0] is list of dicts
                    scores = {d["label"].lower(): float(d["score"]) for d in outputs[0]}
                # Top emotions by score
                top = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)[:5]
                return [k for k, _ in top], scores
            except Exception:
                pass
        # Fallback: simple keyword heuristic
        heuristics = {
            "joy": ["happy", "joy", "smile", "bright", "sunny"],
            "love": ["love", "heart", "romance", "kiss"],
            "melancholy": ["sad", "cry", "blue", "lonely"],
            "anger": ["angry", "rage", "fire", "fight"],
            "mystery": ["dark", "shadow", "secret"],
            "hope": ["hope", "rise", "light"],
        }
        found: Dict[str, float] = {}
        tl = text.lower()
        for label, kws in heuristics.items():
            score = sum(1 for w in kws if w in tl)
            if score:
                found[label] = float(score) / (len(kws) + 1)
        top = sorted(found.items(), key=lambda kv: kv[1], reverse=True)[:5]
        return [k for k, _ in top], found

    def _themes_zero_shot(self, text: str) -> Tuple[List[str], Dict[str, float]]:
        if self._zshot_pipe is not None:
            try:
                res = self._zshot_pipe(text[:4000], candidate_labels=self.theme_labels, multi_label=True)
                labels = [l.lower() for l in res.get("labels", [])]
                scores_raw = res.get("scores", [])
                scores = {labels[i]: float(scores_raw[i]) for i in range(min(len(labels), len(scores_raw)))}
                top = labels[:5]
                return top, scores
            except Exception:
                pass
        # Fallback: pick themes that appear as words
        tl = text.lower()
        scores = {t: (1.0 if t in tl else 0.0) for t in self.theme_labels}
        top = [t for t, v in scores.items() if v > 0.0][:5]
        return top, scores

    def _extract_entities(self, text: str) -> Dict[str, List[str]]:
        ents: Dict[str, List[str]] = {}
        if self._nlp is not None:
            try:
                doc = self._nlp(text[:20000])
                for ent in doc.ents:
                    ents.setdefault(ent.label_, []).append(ent.text)
                # dedupe
                for k, v in list(ents.items()):
                    ents[k] = sorted(list(dict.fromkeys(v)))[:30]
                return ents
            except Exception:
                pass
        # Fallback minimal entity types using regex (very rough)
        proper_nouns = sorted(list(dict.fromkeys(re.findall(r"\b([A-Z][a-z]{2,}(?:\s+[A-Z][a-z]{2,})*)\b", text))))
        if proper_nouns:
            ents["PROPN"] = proper_nouns[:30]
        return ents

    def _extract_visual_imagery(self, text: str, ents: Dict[str, List[str]]) -> List[str]:
        imagery: List[str] = []
        tl = text.lower()
        for kw in self.VISUAL_KEYWORDS:
            if kw in tl:
                imagery.append(kw)
        # Add locations and objects from NER if present
        for k in ("GPE", "LOC", "FAC", "ORG", "PROPN"):
            for v in ents.get(k, [])[:10]:
                # Prefer lowercase phrase tokens as imagery hints
                imagery.append(v.lower())
        # dedupe keeping order
        seen = set()
        return [x for x in imagery if not (x in seen or seen.add(x))][:20]

    def _sentiment(self, text: str, segments: List[str]) -> Tuple[Dict[str, float], List[Tuple[int, float]]]:
        overall: Dict[str, float] = {}
        progression: List[Tuple[int, float]] = []

        # TextBlob overall
        if _TB_OK:
            try:
                blob = TextBlob(text)
                overall["polarity"] = float(blob.sentiment.polarity)
                overall["subjectivity"] = float(blob.sentiment.subjectivity)
            except Exception:
                pass

        # VADER overall + per-segment
        if _NLTK_OK and SentimentIntensityAnalyzer is not None:
            try:
                sia = SentimentIntensityAnalyzer()
                scores = sia.polarity_scores(text)
                overall["vader_compound"] = float(scores.get("compound", 0.0))
                for i, seg in enumerate(segments):
                    sc = sia.polarity_scores(seg)
                    progression.append((i, float(sc.get("compound", 0.0))))
            except Exception:
                pass

        # Fallback per-segment using TextBlob only
        if not progression and _TB_OK:
            try:
                for i, seg in enumerate(segments):
                    sc = TextBlob(seg).sentiment.polarity
                    progression.append((i, float(sc)))
            except Exception:
                pass

        return overall, progression[:50]

    def _narrative_structure(self, text: str) -> str:
        if self._zshot_pipe is not None:
            try:
                res = self._zshot_pipe(text[:4000], candidate_labels=self.NARRATIVE_LABELS, multi_label=False)
                labels = res.get("labels", [])
                return str(labels[0]) if labels else ""
            except Exception:
                pass
        # Fallback heuristic
        tl = text.lower()
        if any(w in tl for w in ("once", "begin", "start")) and any(w in tl for w in ("end", "finally", "resolve")):
            return "rising action"
        return "vignette"


# ---------------------------------------------------------------------------
# AI Prompt Generator (Claude HTTP API)
# ---------------------------------------------------------------------------
class AIPromptGenerator:
    """Generates cinematic prompts via Claude API with a deterministic fallback.

    The generator supports optional AI provider backends (OpenAI-compatible,
    Ollama, llama.cpp, HuggingFace Transformers) with a deterministic fallback.
    When unavailable, it synthesizes high-quality prompts locally using the
    analysis data.
    """

    def __init__(
        self,
        anthropic_api_key: Optional[str] = None,
        model: str = "claude-3-5-sonnet-20240620",
        provider: str = "claude",
        provider_config: Optional[Dict[str, Any]] = None,
    ):
        self.api_key = anthropic_api_key or os.getenv("ANTHROPIC_API_KEY")
        self.model = model
        self.provider = provider
        self._provider = None
        self._provider_error = None
        if provider != "claude" and _AI_PROVIDER_OK and build_ai_provider and AIProviderConfig:
            try:
                config_data = dict(provider_config or {})
                config_data.setdefault("provider", provider)
                self._provider = build_ai_provider(AIProviderConfig(**config_data))
            except Exception as exc:
                self._provider_error = str(exc)

    # Public API
    def generate(self, analysis: Any, lyrics: LyricsAnalysis, num_prompts: int = 6) -> List[str]:
        if self._provider:
            prompt = self._compose_ai_request_text(analysis, lyrics, num_prompts)
            prompts = self._provider.generate_prompts(prompt, num_prompts)
            if prompts:
                return prompts
        if self.provider in {"claude", "anthropic"} and self.api_key and _REQ_OK:
            prompts = self._call_claude_http(analysis, lyrics, num_prompts)
            if prompts:
                return prompts
        # Fallback
        return self._fallback_prompts(analysis, lyrics, num_prompts)

    # -------- internals --------
    def _call_claude_http(self, analysis: Any, lyrics: LyricsAnalysis, num_prompts: int) -> List[str]:
        url = "https://api.anthropic.com/v1/messages"
        if not _REQ_OK or not requests:
            return []
        try:
            payload = {
                "model": self.model,
                "max_tokens": 800,
                "system": (
                    "You are a film director AI that writes vivid, concise Stable Diffusion Deforum prompts. "
                    "Respond ONLY with a JSON array of strings. Each string must be a single shot description, "
                    "describing composition, lens, lighting, color palette, movement, and mood."
                ),
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": self._compose_ai_request_text(analysis, lyrics, num_prompts),
                            }
                        ],
                    }
                ],
            }
            headers = {
                "x-api-key": self.api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json",
            }
            resp = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)
            resp.raise_for_status()
            data = resp.json()
            # Anthropics Messages API returns content as a list with text segments
            text_chunks = []
            for c in data.get("content", []):
                if isinstance(c, dict) and c.get("type") == "text":
                    text_chunks.append(c.get("text", ""))
            combined = "\n".join(text_chunks).strip()
            try:
                arr = json.loads(combined)
                if isinstance(arr, list):
                    return [str(x) for x in arr][:num_prompts]
            except Exception:
                # Attempt to extract JSON array from mixed text
                m = re.search(r"\[(?:.|\n)*\]", combined)
                if m:
                    try:
                        arr = json.loads(m.group(0))
                        if isinstance(arr, list):
                            return [str(x) for x in arr][:num_prompts]
                    except Exception:
                        pass
        except Exception:
            # Network/API errors are silently swallowed; fallback takes over
            return []
        return []

    @staticmethod
    def _compose_ai_request_text(analysis: Any, lyrics: LyricsAnalysis, num_prompts: int) -> str:
        # Pack salient features concisely. Claude prompt is intentionally compact.
        tempo = getattr(analysis, "tempo_bpm", 0.0)
        duration = getattr(analysis, "duration", 0.0)
        energy = getattr(analysis, "energy_segments", [])
        spectral = getattr(analysis, "spectral_features", {})
        visuals = (lyrics.visual_imagery or [])[:6]
        emotions = (lyrics.emotions or [])[:4]
        themes = (lyrics.themes or [])[:3]
        narrative = lyrics.narrative_structure or ""
        return (
            f"Create {num_prompts} video prompts for Stable Diffusion Deforum. "
            f"Music tempo: {tempo:.1f} BPM, duration: {duration:.1f}s. "
            f"Energy trend: {energy[:6]}. Spectral: {spectral}. "
            f"Dominant emotions: {emotions}. Themes: {themes}. Narrative: {narrative}. "
            f"Visual motifs: {visuals}. Each prompt must be <= 35 words."
        )

    @staticmethod
    def _fallback_prompts(analysis: Any, lyrics: LyricsAnalysis, num_prompts: int) -> List[str]:
        # Build deterministic, high-quality prompts from available signals
        tempo = getattr(analysis, "tempo_bpm", 0.0)
        energy_vals: List[float] = list(getattr(analysis, "energy_segments", []) or [0.5])
        brightness = float(getattr(analysis, "spectral_features", {}).get("brightness", 0.5))
        warmth = float(getattr(analysis, "spectral_features", {}).get("warmth", 0.5))
        visuals = (lyrics.visual_imagery or ["cinematic scenery"])[:6]
        emotions = (lyrics.emotions or ["atmospheric"])[:3]
        themes = (lyrics.themes or ["abstract"])[:2]

        def style_bits() -> List[str]:
            out: List[str] = []
            if brightness > 0.6:
                out.append("high key, vivid colors")
            elif brightness < 0.35:
                out.append("low key, moody shadows")
            if warmth > 0.6:
                out.append("warm tones, golden hour glow")
            elif warmth < 0.35:
                out.append("cool tones, cyan-blue palette")
            if tempo >= 120:
                out.append("dynamic movement")
            elif tempo <= 70:
                out.append("gentle drift")
            return out

        extras = ", ".join(style_bits())
        base = [
            f"{v}, {extras}, emotion: {emotions[0]}, theme: {themes[0]}, 35mm lens, shallow depth of field, cinematic lighting"
            for v in visuals
        ]
        # pad/cycle to num_prompts
        out: List[str] = []
        i = 0
        while len(out) < num_prompts and base:
            out.append(base[i % len(base)])
            i += 1
        return out[:num_prompts]


# ---------------------------------------------------------------------------
# Decorator/Factory: wraps an existing AudioAnalyzer to add NLP + AI
# ---------------------------------------------------------------------------
def integrate_enhanced_nlp(BaseAnalyzerClass: Any):
    """Return a subclass of the given AudioAnalyzer that adds NLP/AI features.

    The returned class preserves the original API:
    - analyze(audio_path, enable_lyrics: bool = False, **kwargs) -> AudioAnalysis
    Additional kwargs supported:
    - enable_ai_prompts: bool = False
    - claude_api_key: Optional[str] = None  (also read from env ANTHROPIC_API_KEY)
    - ai_provider: str = "claude"
    - ai_provider_config: Optional[Dict[str, Any]] = None
    - theme_labels: Optional[List[str]]
    - spacy_model: str = "en_core_web_sm"

    Notes
    -----
    The base analyzer is expected to set `analysis.raw_text` when lyrics are
    available (e.g., via Whisper), as in your current implementation
    (`AudioAnalyzer.analyze` populates `raw_text` when enabled). The enhanced
    results are attached to `analysis.enhanced_lyrics`.
    """

    class EnhancedAudioAnalyzer(BaseAnalyzerClass):  # type: ignore[misc]
        def __init__(
            self,
            *args: Any,
            claude_api_key: Optional[str] = None,
            spacy_model: str = "en_core_web_sm",
            theme_labels: Optional[List[str]] = None,
            ai_provider: str = "claude",
            ai_provider_config: Optional[Dict[str, Any]] = None,
            **kwargs: Any,
        ) -> None:
            super().__init__(*args, **kwargs)
            self._nlp_analyzer = EnhancedNLPAnalyzer(spacy_model=spacy_model, theme_labels=theme_labels)
            self._ai_prompter = AIPromptGenerator(
                anthropic_api_key=claude_api_key,
                provider=ai_provider,
                provider_config=ai_provider_config,
            )

        def analyze(self, audio_path: str, enable_lyrics: bool = False, enable_ai_prompts: bool = False, **kwargs: Any):  # type: ignore[override]
            # Run the base analysis first
            analysis = super().analyze(audio_path, enable_lyrics=enable_lyrics)

            # If lyric text is present, augment with NLP
            text = getattr(analysis, "raw_text", "") or ""
            if text.strip():
                try:
                    la = self._nlp_analyzer.analyze_text(text)
                    setattr(analysis, "enhanced_lyrics", la)

                    # Optionally attach AI prompts
                    if enable_ai_prompts:
                        try:
                            la.ai_generated_prompts = self._ai_prompter.generate(analysis, la, num_prompts=6)
                        except Exception as e:
                            # Keep analysis intact even if AI prompt generation fails
                            la.warnings.append(f"AI prompt generation failed: {e}")
                except Exception as e:
                    # Never break the base pipeline
                    try:
                        # Attach a minimal placeholder with the error
                        placeholder = LyricsAnalysis(warnings=[f"Enhanced NLP failed: {e}"])
                        setattr(analysis, "enhanced_lyrics", placeholder)
                    except Exception:
                        pass
            else:
                # Ensure attribute exists for UI simplicity
                setattr(analysis, "enhanced_lyrics", LyricsAnalysis(warnings=["No lyrics available; NLP skipped."]))

            return analysis

    return EnhancedAudioAnalyzer


# ---------------------------------------------------------------------------
# Utilities for direct/local testing (optional)
# ---------------------------------------------------------------------------
if __name__ == "__main__":
    # Minimal smoke test on a snippet of text; no audio required
    sample_text = (
        "Under neon city skies we run, hearts on fire, chasing freedom. "
        "Shadows fade as morning comes, our fears dissolve in ocean light."
    )
    nlp = EnhancedNLPAnalyzer()
    la = nlp.analyze_text(sample_text)
    print("\n[Enhanced NLP]", json.dumps(la.to_dict(), indent=2))

    # Fallback AI prompt generation demo (no API key required)
    class _Dummy:
        tempo_bpm = 122.0
        duration = 180.0
        energy_segments = [0.25, 0.4, 0.6, 0.8, 0.7]
        spectral_features = {"brightness": 0.62, "warmth": 0.55}

    prompter = AIPromptGenerator(anthropic_api_key=None)
    demo_prompts = prompter.generate(_Dummy(), la, num_prompts=4)
    print("\n[AI Prompts]", json.dumps(demo_prompts, indent=2))
